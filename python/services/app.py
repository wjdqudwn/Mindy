import soundfile as sf
import numpy as np
import librosa
import torch
from df.enhance import enhance, init_df


def calculate_metrics(original, processed):
    min_len = min(len(original), len(processed))
    original = original[:min_len]
    processed = processed[:min_len]
    noise = original - processed

    noise_power = np.mean(noise ** 2) + 1e-10
    orig_power = np.mean(original ** 2) + 1e-10
    proc_power = np.mean(processed ** 2) + 1e-10

    snr_before = 10 * np.log10(orig_power / noise_power)
    snr_after = 10 * np.log10(proc_power / noise_power)

    return {
        'SNR_ê°œì„ (dB)': snr_after - snr_before,
        'ì›ë³¸_RMS': np.sqrt(orig_power),
        'ì²˜ë¦¬í›„_RMS': np.sqrt(proc_power),
        'ì œê±°ëœ_ì†ŒìŒ_RMS': np.sqrt(noise_power),
        'ì”ë¥˜ì†ŒìŒ_ë¹„ìœ¨(%)': (noise_power / orig_power) * 100
    }


def process_audio_files(file_list):
    model, df_state, _ = init_df()

    results = {}
    for file in file_list:
        audio, sr = librosa.load(file, sr=48000)
        audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)  # (T,) â†’ (1, T)

        processed_tensor = enhance(
            model,
            df_state,
            audio_tensor,
            atten_lim_db=75.0
        )

        processed = processed_tensor.squeeze(0).cpu().numpy()  # (1, T) â†’ (T,)
        sf.write(f'cleaned_{file}', processed, sr)
        results[file] = calculate_metrics(audio, processed)
    return results


if __name__ == "__main__":
    input_files = ['1.wav']
    processing_results = process_audio_files(input_files)

    for file, metrics in processing_results.items():
        print(f"\nğŸ“Š {file} ë¶„ì„ ê²°ê³¼:")
        print(f"- SNR ê°œì„ ëŸ‰: {metrics['SNR_ê°œì„ (dB)']:.2f} dB")
        print(f"- ì›ë³¸ ì‹ í˜¸ ê°•ë„: {metrics['ì›ë³¸_RMS']:.4f}")
        print(f"- ì²˜ë¦¬ í›„ ì‹ í˜¸ ê°•ë„: {metrics['ì²˜ë¦¬í›„_RMS']:.4f}")
        print(f"- ì œê±°ëœ ì†ŒìŒ ë ˆë²¨: {metrics['ì œê±°ëœ_ì†ŒìŒ_RMS']:.4f}")
        print(f"- ì”ë¥˜ ì†ŒìŒ ë¹„ìœ¨: {metrics['ì”ë¥˜ì†ŒìŒ_ë¹„ìœ¨(%)']:.2f}%")
